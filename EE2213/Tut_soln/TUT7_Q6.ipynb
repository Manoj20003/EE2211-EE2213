{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV7AEQQUyK8N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# load the wine dataset as a dictionary-like object\n",
    "wine = load_wine()\n",
    "print(\"Wine dataset keys:\", wine.keys())\n",
    "print(\"Wine dataset description:\", wine.DESCR) # Description of the dataset\n",
    "\n",
    "X = wine.data # numpy.ndarray\n",
    "y = wine.target # numpy.ndarray\n",
    "\n",
    "print(\"Wine dataset feature matrix:\", X)\n",
    "print(\"Wine dataset target vector:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7wSMSQyydZp"
   },
   "outputs": [],
   "source": [
    "def k_means(data_points, centers_init, n_clusters, max_iterations=100, tol=1e-4):\n",
    "  centers = centers_init.copy() # make a copy of initial center to work on.\n",
    "  for _ in range(max_iterations): # The underscore _ is a throwaway variable, meaning “I don’t care about the loop variable.”\n",
    "\n",
    "    # Compute squared Euclidean distances to each centroid\n",
    "    # Result shape: (n_samples, k)\n",
    "    distances = np.linalg.norm(data_points[:, np.newaxis] - centers, axis=2)\n",
    "\n",
    "    # Assign each point to the index of the closest centroid\n",
    "    closest_centroids = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Update centroids to be the mean of the data points assigned to them\n",
    "    new_centers = np.zeros((n_clusters, data_points.shape[1]))\n",
    "    # End if centroids no longer change\n",
    "    for i in range(n_clusters):\n",
    "      new_centers[i] = data_points[closest_centroids == i].mean(axis=0)\n",
    "\n",
    "    if np.linalg.norm(new_centers - centers) < tol:\n",
    "      break\n",
    "    centers = new_centers\n",
    "  return centers, closest_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4Dpn_1p01NJ"
   },
   "outputs": [],
   "source": [
    "J = {} # Dictionary to store within-cluster variance for each k\n",
    "np.random.seed(42)  # For reproducibility\n",
    "for n_clusters in range(2, 11):\n",
    "\n",
    "    # Randomly initialize cluster centers by selecting k unique data points\n",
    "    centers_init = X[np.random.choice(X.shape[0], n_clusters, replace=False)]  \n",
    "    # np.random.choice(): Randomly selects n_clusters unique indices from 0 … n_samples-1.\n",
    "    #                     replace=False ensures no duplicate picks.\n",
    "    centers, labels = k_means(X, centers_init, n_clusters=n_clusters)\n",
    "    within_cluster_var = np.sum((X - centers[labels]) ** 2) # sum of squared distances to the assigned centroid.\n",
    "    J[n_clusters] = within_cluster_var\n",
    "    print(f\"Converged centers for {n_clusters} clusters:\", centers)\n",
    "    print(f\"Within-cluster variance for {n_clusters} clusters:\", within_cluster_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the within-cluster variance over the number of clusters\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(J.keys(), J.values(), marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Within-cluster variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "J = {}\n",
    "np.random.seed(42)  # For reproducibility\n",
    "for n_clusters in range(2, 11):\n",
    "    centers_init = X[np.random.choice(X.shape[0], n_clusters, replace = False)] # np.random.choice(): k random indices.\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init=centers_init, n_init=1)\n",
    "    #n_init: The number of times the KMeans algorithm will run with different centroid seeds\n",
    "    #        Setting n_init=1 means it will only run once, using the given centers_init\n",
    "    kmeans.fit(X)\n",
    "    within_cluster_var = np.sum((X - kmeans.cluster_centers_[kmeans.labels_]) ** 2)\n",
    "    J[n_clusters] = within_cluster_var\n",
    "    print(f\"Within-cluster variance for {n_clusters} clusters:\", within_cluster_var)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(J.keys()), list(J.values()), marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Within-cluster variance')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ee2213",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
